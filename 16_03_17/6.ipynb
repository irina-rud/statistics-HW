{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.special import gamma, binom,gammaln,factorial\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "N = [100,250, 500]\n",
    "Alp = [0.01, 0.05, 0.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wald_wolfowitz(X):\n",
    "    mean = np.mean(X)\n",
    "    sequence = np.sign(X - mean)\n",
    "    n_runs = sum(1 for s in groupby(sequence, lambda a: a))\n",
    "    \n",
    "    n = float(sum(1 for s in sequence if s == sequence[0]))\n",
    "    m = float(sum(1 for s in sequence if s != sequence[0]))\n",
    "\n",
    "    mean  = ((2 * n * m ) / (n + m)) + 1\n",
    "    var = (2 * n * m * (2 * n * m - n - m )) / ((n + m)**2 * (n + m - 1))\n",
    "    if var**2 == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return (n_runs - mean) / var**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = [\n",
    "    stats.alpha(a=3.57, loc=0.0, scale=1.0), stats.anglit(loc=0.0, scale=1.0), \n",
    "    stats.arcsine(loc=0.0, scale=1.0), stats.beta(a=2.31, b=0.627, loc=0.0, scale=1.0), \n",
    "    stats.betaprime(a=5, b=6, loc=0.0, scale=1.0), stats.bradford(c=0.299, loc=0.0, scale=1.0),\n",
    "    stats.burr(c=10.5, d=4.3, loc=0.0, scale=1.0), stats.cauchy(loc=0.0, scale=1.0), \n",
    "    stats.chi(df=78, loc=0.0, scale=1.0), stats.chi2(df=55, loc=0.0, scale=1.0),\n",
    "    stats.cosine(loc=0.0, scale=1.0), stats.dgamma(a=1.1, loc=0.0, scale=1.0), \n",
    "    stats.dweibull(c=2.07, loc=0.0, scale=1.0), stats.erlang(a=2, loc=0.0, scale=1.0), \n",
    "    stats.expon(loc=0.0, scale=1.0), stats.exponnorm(K=1.5, loc=0.0, scale=1.0),\n",
    "    stats.exponweib(a=2.89, c=1.95, loc=0.0, scale=1.0), stats.exponpow(b=2.7, loc=0.0, scale=1.0),\n",
    "    stats.f(dfn=29, dfd=18, loc=0.0, scale=1.0), stats.fatiguelife(c=29, loc=0.0, scale=1.0), \n",
    "    stats.fisk(c=3.09, loc=0.0, scale=1.0), stats.foldcauchy(c=4.72, loc=0.0, scale=1.0),\n",
    "    stats.foldnorm(c=1.95, loc=0.0, scale=1.0), stats.frechet_r(c=1.89, loc=0.0, scale=1.0),\n",
    "    stats.frechet_l(c=3.63, loc=0.0, scale=1.0), stats.genlogistic(c=0.412, loc=0.0, scale=1.0),\n",
    "    stats.genpareto(c=0.1, loc=0.0, scale=1.0), stats.gennorm(beta=1.3, loc=0.0, scale=1.0), \n",
    "    stats.genexpon(a=9.13, b=16.2, c=3.28, loc=0.0, scale=1.0), stats.genextreme(c=-0.1, loc=0.0, scale=1.0),\n",
    "    stats.gausshyper(a=13.8, b=3.12, c=2.51, z=5.18, loc=0.0, scale=1.0), stats.gamma(a=1.99, loc=0.0, scale=1.0),\n",
    "    stats.gengamma(a=4.42, c=-3.12, loc=0.0, scale=1.0), stats.genhalflogistic(c=0.773, loc=0.0, scale=1.0),\n",
    "    stats.gilbrat(loc=0.0, scale=1.0), stats.gompertz(c=0.947, loc=0.0, scale=1.0),\n",
    "    stats.gumbel_r(loc=0.0, scale=1.0), stats.gumbel_l(loc=0.0, scale=1.0),\n",
    "    stats.halfcauchy(loc=0.0, scale=1.0), stats.halflogistic(loc=0.0, scale=1.0),\n",
    "    stats.halfnorm(loc=0.0, scale=1.0), stats.halfgennorm(beta=0.675, loc=0.0, scale=1.0),\n",
    "    stats.hypsecant(loc=0.0, scale=1.0), stats.invgamma(a=4.07, loc=0.0, scale=1.0),\n",
    "    stats.invgauss(mu=0.145, loc=0.0, scale=1.0), stats.invweibull(c=10.6, loc=0.0, scale=1.0),\n",
    "    stats.johnsonsb(a=4.32, b=3.18, loc=0.0, scale=1.0), stats.johnsonsu(a=2.55, b=2.25, loc=0.0, scale=1.0),\n",
    "    stats.ksone(n=1e+03, loc=0.0, scale=1.0), stats.kstwobign(loc=0.0, scale=1.0),\n",
    "    stats.laplace(loc=0.0, scale=1.0), stats.levy(loc=0.0, scale=1.0),\n",
    "    stats.levy_l(loc=0.0, scale=1.0), stats.levy_stable(alpha=0.357, beta=-0.675, loc=0.0, scale=1.0),\n",
    "    stats.logistic(loc=0.0, scale=1.0), stats.loggamma(c=0.414, loc=0.0, scale=1.0),\n",
    "    stats.loglaplace(c=3.25, loc=0.0, scale=1.0), stats.lognorm(s=0.954, loc=0.0, scale=1.0),\n",
    "    stats.lomax(c=1.88, loc=0.0, scale=1.0), stats.maxwell(loc=0.0, scale=1.0),\n",
    "    stats.mielke(k=10.4, s=3.6, loc=0.0, scale=1.0), stats.nakagami(nu=4.97, loc=0.0, scale=1.0),\n",
    "    stats.ncx2(df=21, nc=1.06, loc=0.0, scale=1.0), stats.ncf(dfn=27, dfd=27, nc=0.416, loc=0.0, scale=1.0),\n",
    "    stats.nct(df=14, nc=0.24, loc=0.0, scale=1.0), stats.norm(loc=0.0, scale=1.0),\n",
    "    stats.pareto(b=2.62, loc=0.0, scale=1.0), stats.pearson3(skew=0.1, loc=0.0, scale=1.0),\n",
    "    stats.powerlaw(a=1.66, loc=0.0, scale=1.0), stats.powerlognorm(c=2.14, s=0.446, loc=0.0, scale=1.0),\n",
    "    stats.powernorm(c=4.45, loc=0.0, scale=1.0), stats.rdist(c=0.9, loc=0.0, scale=1.0),\n",
    "    stats.reciprocal(a=0.00623, b=1.01, loc=0.0, scale=1.0), stats.rayleigh(loc=0.0, scale=1.0),\n",
    "    stats.rice(b=0.775, loc=0.0, scale=1.0), stats.recipinvgauss(mu=0.63, loc=0.0, scale=1.0),\n",
    "    stats.semicircular(loc=0.0, scale=1.0), stats.t(df=2.74, loc=0.0, scale=1.0),\n",
    "    stats.triang(c=0.158, loc=0.0, scale=1.0), stats.truncexpon(b=4.69, loc=0.0, scale=1.0),\n",
    "    stats.truncnorm(a=0.1, b=2, loc=0.0, scale=1.0), stats.tukeylambda(lam=3.13, loc=0.0, scale=1.0),\n",
    "    stats.uniform(loc=0.0, scale=1.0), stats.vonmises(kappa=3.99, loc=0.0, scale=1.0),\n",
    "    stats.vonmises_line(kappa=3.99, loc=0.0, scale=1.0), stats.wald(loc=0.0, scale=1.0),\n",
    "    stats.weibull_min(c=1.79, loc=0.0, scale=1.0), stats.weibull_max(c=2.87, loc=0.0, scale=1.0),\n",
    "    stats.wrapcauchy(c=0.0311, loc=0.0, scale=1.0)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_criteria_samples(n, size = 100, alpha = 2, beta = 2,gam = 0.5, delta = 2, m = 20):\n",
    "    criteria_samples = []\n",
    "    for i in range(size):\n",
    "        samples = [1 * (np.round(distr.rvs(size=n)) % 2 ) for distr in DISTRIBUTIONS]\n",
    "        for sample in samples:\n",
    "            ww = wald_wolfowitz(sample)\n",
    "            if (ww!=None):\n",
    "                criteria_samples.append(ww)\n",
    "\n",
    "    return criteria_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "При размере выборки 100, alpha= 0.01 : критерий: {K(X) >= 52.06}\n",
      "При размере выборки 100, alpha= 0.05 : критерий: {K(X) >= 2.05}\n",
      "При размере выборки 100, alpha= 0.10 : критерий: {K(X) >= 0.39}\n",
      "При размере выборки 250, alpha= 0.01 : критерий: {K(X) >= 14.30}\n",
      "При размере выборки 250, alpha= 0.05 : критерий: {K(X) >= 1.13}\n",
      "При размере выборки 250, alpha= 0.10 : критерий: {K(X) >= 0.04}\n",
      "При размере выборки 500, alpha= 0.01 : критерий: {K(X) >= 10.23}\n",
      "При размере выборки 500, alpha= 0.05 : критерий: {K(X) >= 0.86}\n",
      "При размере выборки 500, alpha= 0.10 : критерий: {K(X) >= 0.03}\n"
     ]
    }
   ],
   "source": [
    "quantiles = []\n",
    "for i in range(3):\n",
    "    criteria_samples = create_criteria_samples(N[i], size = 10**1)\n",
    "    qw = []\n",
    "    for j in range(3):\n",
    "        quantile = sps.mstats.mquantiles(criteria_samples,1 - (Alp[j])/2)\n",
    "        qw.append(quantile)\n",
    "        print('При размере выборки %d, alpha= %.2f : критерий: {K(X) >= %.2f}' % (N[i], Alp[j], quantile))\n",
    "    quantiles.append(qw)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Критерий Вальда-Вольфовица говорит нам :[False] при уровне доверия 0.05\n",
      "значение статистики при этом: -0.061\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('sample2.csv', header = None)\n",
    "sample = np.array(data.values[:,0])\n",
    "\n",
    "stat = wald_wolfowitz(sample)\n",
    "\n",
    "print (\"Критерий Вальда-Вольфовица говорит нам :\" + str(np.abs(stat) >= quantiles[2][1] )+ \" при уровне доверия 0.05\")\n",
    "print (\"значение статистики при этом: %.3f\" % stat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну то есть при уровне доверия в 0,1 можно"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
